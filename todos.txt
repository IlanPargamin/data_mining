# Ilan - done
def get_page_html(urls):
    """
    using beautifulsoup module, we collect the html "soup" of all the website's relevant urls
    of the main page: www.freelancer.com/jobs.
    We return a list of soups.
    """
    return soups_main

# Shai
def get_project_html(sub_urls):
    """
    using beautifulsoup module, we collect the html "soup" of all the website's relevant urls
    of the projects sub pages: https://www.freelancer.com/projects/cplusplus-programming/assistance-33051135.
    We return a list of soups.
    """
    return soups_project

# Ilan - done
def scrape_main_page(list_of_soups, parameters=True):
    """
    For each parameter, returns a list of scraped data from the main page if parameter True
    :param soup
    :param titles
    :param days_left
    :param job_desc
    :param tags
    :param bids
    :param links
    :return: out: a dictionary where each True parameter is a key and the associated value is the list of scraped data
    """
    return dict_main

# Shai
def scrape_project_page(list_of_soups):
    """
    For each parameter, returns a list of scraped data from the subproject page if parameter True
    :param soup
    :param titles
    :param days_left
    :param job_desc
    :param tags
    :param bids
    :param links
    :return: out: a dictionary where each True parameter is a key and the associated value is the list of scraped data

    """
    return dict_project

# Ilan
join_scrapes(dict_main, dict_project)
    """
    join dict_main and dict_project into one dictionary 
    """
    return dict

# Ilan - done
requirements.txt 
README.md